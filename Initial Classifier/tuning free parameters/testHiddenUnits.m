% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created 03-Dec-2016 13:46:39
%
% This script assumes these variables are defined:
% Lambda vs error rate 

D= importdata('handwriting.data');
samples= size(D,1);
Y= D(:,1);
trainX= D(:,2:end);

for i=1:samples
    trainY(i,Y(i,1)+1) = 1;
end
x = trainX';
t = trainY';
h_size = round(linspace(100,600,10));
n_randomrestart = 5;
accs = zeros(n_randomrestart,numel(h_size));
test_accs = zeros(n_randomrestart,numel(h_size));
train_accs = zeros(n_randomrestart,numel(h_size));

test_errs = zeros(n_randomrestart,numel(h_size));
train_errs = zeros(n_randomrestart,numel(h_size));

val_accs = zeros(n_randomrestart,numel(h_size));
%Random restarts 
for i=1:n_randomrestart
    for j= 1: numel(h_size)
       lambda = 0.1;
        trainFcn = 'trainscg';  % Scaled conjugate gradient backpropagation.

         % Create a Pattern Recognition Network
         hiddenLayerSize = h_size(j);
         net = patternnet(hiddenLayerSize, trainFcn);
         
         net.layers{1}.transferFcn = 'tansig';
        % Setup Division of Data for Training, Validation, Testing
        net.divideFcn = 'divideblock';
        [trainInd,valInd,testInd] = divideblock(x,75/100,15/100,10/100);

        net.performParam.regularization =lambda;
        % Train the Network
        [net,tr] = train(net,x,t);

        % Overall Performance
        outputs = net(x);
        e = gsubtract(t,outputs);
        performance = perform(net,t,outputs);

     
        yind = vec2ind(outputs);
        tind = vec2ind(t);
        % accuracy
        accs(i,j) = sum(tind == yind)/ numel(yind);
         
        %Train Performance
        trInd = tr.trainInd;
        trOutputs = net(x(:,trInd));
        trPerform = perform(net,t(:,trInd),trOutputs);
        yind = vec2ind(trOutputs);
        tind = vec2ind(t(:,trInd));
        
        % accuracy
        train_accs(i,j) = sum(tind == yind)/ numel(yind);
        %Error
        train_errs(i,j) = sum(tind ~= yind)/ numel(yind);
        
        %Test Performance
        tInd = tr.testInd;
        tstOutputs = net(x(:,tInd));
        tstPerform = perform(net,t(:,tInd),tstOutputs);
        yind = vec2ind(tstOutputs);
        tind = vec2ind(t(:,tInd));
        
        % accuracy
        test_accs(i,j) = sum(tind == yind)/ numel(yind);
        %Error
        test_errs(i,j) = sum(tind ~= yind)/ numel(yind);
        
        %Validation Performance
        vInd = tr.valInd;
        valOutputs = net(x(:,vInd));
        valPerform = perform(net,t(:,vInd),valOutputs);
        yind = vec2ind(valOutputs);
        tind = vec2ind(t(:,vInd));
        
        % accuracy
        val_accs(i,j) = sum(tind == yind)/ numel(yind);
   end
end      



acc= max(max(accs)); %Maximum Overall Accuracy
testAcc= max(max(test_accs)); %Maximum Test Accuracy
trainAcc= max(max(train_accs)); %Maximum Train Accuracy
valAcc= max(max(val_accs)); %Maximum Test Accuracy


%Plotting the average over random restarts for both training and testing
%error

plot(h_size,(sum(test_errs,1)/5),'r',h_size,(sum(train_errs,1)/5),'b');
legend('Test Error Rate','Train Error Rate');

xlabel('Number of Hidden Units');
ylabel('Error Rate');
